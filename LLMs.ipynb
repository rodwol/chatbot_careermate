{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # **Career and Job Search Assistant**\n",
    "A domain-specific assistant is an AI assistant that is trained to focus on one particular field instead of knowing a little about everything. This assistant is specialized in helping entry-level job seekers improve resumes, prepare for interviews, and understand job search strategies. It focuses on ATS optimization, resume bullet improvement, and interview preparation. We are going to use a large language model (pre-trained model) and train it again on the specific dataset so that it becomes a specialized support in job hunting.\n",
    "New imports are used for this task such as **Dataset** which is from **Hugging Face's dataset library** converting data into a foramt optimized for training LLMs as hugging face expect the datat in their Dataset format.\n",
    "# **Objective**\n",
    "\n",
    "\n",
    "- Develop an AI assistant trained to help entry-level job seekers improve resumes, prepare for interviews, and optimize job search strategies.\n",
    "\n",
    "\n",
    "*   Dataset: Curate at 3000 Q&A resume tips for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kagglehub\n",
      "  Downloading kagglehub-1.0.0-py3-none-any.whl.metadata (40 kB)\n",
      "Collecting kagglesdk<1.0,>=0.1.14 (from kagglehub)\n",
      "  Downloading kagglesdk-0.1.15-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from kagglehub) (25.0)\n",
      "Requirement already satisfied: pyyaml in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from kagglehub) (6.0.3)\n",
      "Requirement already satisfied: requests in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from kagglehub) (2.32.5)\n",
      "Collecting tqdm (from kagglehub)\n",
      "  Downloading tqdm-4.67.3-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting protobuf (from kagglesdk<1.0,>=0.1.14->kagglehub)\n",
      "  Downloading protobuf-6.33.5-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from requests->kagglehub) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from requests->kagglehub) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from requests->kagglehub) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from requests->kagglehub) (2026.1.4)\n",
      "Downloading kagglehub-1.0.0-py3-none-any.whl (70 kB)\n",
      "Downloading kagglesdk-0.1.15-py3-none-any.whl (160 kB)\n",
      "Downloading protobuf-6.33.5-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\n",
      "Downloading tqdm-4.67.3-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, protobuf, kagglesdk, kagglehub\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [kagglehub]/4\u001b[0m [kagglehub]\n",
      "\u001b[1A\u001b[2KSuccessfully installed kagglehub-1.0.0 kagglesdk-0.1.15 protobuf-6.33.5 tqdm-4.67.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m26.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m26.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m26.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade kagglehub\n",
    "!pip install pandas datasets transformers -q\n",
    "!pip install transformers datasets accelerate peft bitsandbytes -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplot\n",
      "  Downloading matplot-0.1.9-py2.py3-none-any.whl.metadata (241 bytes)\n",
      "Collecting pyloco>=0.0.134 (from matplot)\n",
      "  Downloading pyloco-0.0.139-py2.py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting matplotlib>=3.1.1 (from matplot)\n",
      "  Downloading matplotlib-3.10.8-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (52 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib>=3.1.1->matplot)\n",
      "  Downloading contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib>=3.1.1->matplot)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib>=3.1.1->matplot)\n",
      "  Downloading fonttools-4.61.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (114 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib>=3.1.1->matplot)\n",
      "  Downloading kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from matplotlib>=3.1.1->matplot) (2.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from matplotlib>=3.1.1->matplot) (25.0)\n",
      "Collecting pillow>=8 (from matplotlib>=3.1.1->matplot)\n",
      "  Downloading pillow-12.1.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
      "Collecting pyparsing>=3 (from matplotlib>=3.1.1->matplot)\n",
      "  Downloading pyparsing-3.3.2-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from matplotlib>=3.1.1->matplot) (2.9.0.post0)\n",
      "Collecting ushlex (from pyloco>=0.0.134->matplot)\n",
      "  Downloading ushlex-0.99.1.tar.gz (4.7 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: websocket-client in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from pyloco>=0.0.134->matplot) (1.9.0)\n",
      "Collecting twine (from pyloco>=0.0.134->matplot)\n",
      "  Downloading twine-6.2.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting typing (from pyloco>=0.0.134->matplot)\n",
      "  Downloading typing-3.7.4.3.tar.gz (78 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting SimpleWebSocketServer (from pyloco>=0.0.134->matplot)\n",
      "  Downloading SimpleWebSocketServer-0.1.2.tar.gz (10 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=3.1.1->matplot) (1.17.0)\n",
      "Collecting readme-renderer>=35.0 (from twine->pyloco>=0.0.134->matplot)\n",
      "  Downloading readme_renderer-44.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: requests>=2.20 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from twine->pyloco>=0.0.134->matplot) (2.32.5)\n",
      "Collecting requests-toolbelt!=0.9.0,>=0.8.0 (from twine->pyloco>=0.0.134->matplot)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from twine->pyloco>=0.0.134->matplot) (2.6.3)\n",
      "Collecting keyring>=21.2.0 (from twine->pyloco>=0.0.134->matplot)\n",
      "  Downloading keyring-25.7.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting rfc3986>=1.4.0 (from twine->pyloco>=0.0.134->matplot)\n",
      "  Downloading rfc3986-2.0.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: rich>=12.0.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from twine->pyloco>=0.0.134->matplot) (14.3.3)\n",
      "Collecting id (from twine->pyloco>=0.0.134->matplot)\n",
      "  Downloading id-1.6.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting SecretStorage>=3.2 (from keyring>=21.2.0->twine->pyloco>=0.0.134->matplot)\n",
      "  Downloading secretstorage-3.5.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting jeepney>=0.4.2 (from keyring>=21.2.0->twine->pyloco>=0.0.134->matplot)\n",
      "  Downloading jeepney-0.9.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jaraco.classes (from keyring>=21.2.0->twine->pyloco>=0.0.134->matplot)\n",
      "  Downloading jaraco.classes-3.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting jaraco.functools (from keyring>=21.2.0->twine->pyloco>=0.0.134->matplot)\n",
      "  Downloading jaraco_functools-4.4.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting jaraco.context (from keyring>=21.2.0->twine->pyloco>=0.0.134->matplot)\n",
      "  Downloading jaraco_context-6.1.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting nh3>=0.2.14 (from readme-renderer>=35.0->twine->pyloco>=0.0.134->matplot)\n",
      "  Downloading nh3-0.3.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting docutils>=0.21.2 (from readme-renderer>=35.0->twine->pyloco>=0.0.134->matplot)\n",
      "  Downloading docutils-0.22.4-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: Pygments>=2.5.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from readme-renderer>=35.0->twine->pyloco>=0.0.134->matplot) (2.19.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from requests>=2.20->twine->pyloco>=0.0.134->matplot) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from requests>=2.20->twine->pyloco>=0.0.134->matplot) (3.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from requests>=2.20->twine->pyloco>=0.0.134->matplot) (2026.1.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from rich>=12.0.0->twine->pyloco>=0.0.134->matplot) (4.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->twine->pyloco>=0.0.134->matplot) (0.1.2)\n",
      "Collecting cryptography>=2.0 (from SecretStorage>=3.2->keyring>=21.2.0->twine->pyloco>=0.0.134->matplot)\n",
      "  Downloading cryptography-46.0.5-cp311-abi3-manylinux_2_34_x86_64.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: cffi>=2.0.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from cryptography>=2.0->SecretStorage>=3.2->keyring>=21.2.0->twine->pyloco>=0.0.134->matplot) (2.0.0)\n",
      "Requirement already satisfied: pycparser in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from cffi>=2.0.0->cryptography>=2.0->SecretStorage>=3.2->keyring>=21.2.0->twine->pyloco>=0.0.134->matplot) (3.0)\n",
      "Collecting more-itertools (from jaraco.classes->keyring>=21.2.0->twine->pyloco>=0.0.134->matplot)\n",
      "  Downloading more_itertools-10.8.0-py3-none-any.whl.metadata (39 kB)\n",
      "Downloading matplot-0.1.9-py2.py3-none-any.whl (5.0 kB)\n",
      "Downloading matplotlib-3.10.8-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m93.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (362 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.61.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m112.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-12.1.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m94.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyloco-0.0.139-py2.py3-none-any.whl (60 kB)\n",
      "Downloading pyparsing-3.3.2-py3-none-any.whl (122 kB)\n",
      "Downloading twine-6.2.0-py3-none-any.whl (42 kB)\n",
      "Downloading keyring-25.7.0-py3-none-any.whl (39 kB)\n",
      "Downloading jeepney-0.9.0-py3-none-any.whl (49 kB)\n",
      "Downloading readme_renderer-44.0-py3-none-any.whl (13 kB)\n",
      "Downloading docutils-0.22.4-py3-none-any.whl (633 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m633.2/633.2 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nh3-0.3.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (811 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m811.5/811.5 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading rfc3986-2.0.0-py2.py3-none-any.whl (31 kB)\n",
      "Downloading secretstorage-3.5.0-py3-none-any.whl (15 kB)\n",
      "Downloading cryptography-46.0.5-cp311-abi3-manylinux_2_34_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading id-1.6.1-py3-none-any.whl (14 kB)\n",
      "Downloading jaraco.classes-3.4.0-py3-none-any.whl (6.8 kB)\n",
      "Downloading jaraco_context-6.1.0-py3-none-any.whl (7.1 kB)\n",
      "Downloading jaraco_functools-4.4.0-py3-none-any.whl (10 kB)\n",
      "Downloading more_itertools-10.8.0-py3-none-any.whl (69 kB)\n",
      "Building wheels for collected packages: SimpleWebSocketServer, typing, ushlex\n",
      "  Building wheel for SimpleWebSocketServer (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for SimpleWebSocketServer: filename=simplewebsocketserver-0.1.2-py3-none-any.whl size=9715 sha256=4f62608933e3ce9b58aa91fb0c5957a506d8e14e251af45829821ded3bae289e\n",
      "  Stored in directory: /home/zeus/.cache/pip/wheels/81/fd/d8/f145b47bedceb5dff96b76e404a4ee9be956a4f8f150cd8133\n",
      "  Building wheel for typing (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for typing: filename=typing-3.7.4.3-py3-none-any.whl size=26396 sha256=b7896d8303c08b4d160f7f09b81636b1bccfee7bd128f8f2f3d4a6bdc205a011\n",
      "  Stored in directory: /home/zeus/.cache/pip/wheels/12/98/52/2bffe242a9a487f00886e43b8ed8dac46456702e11a0d6abef\n",
      "  Building wheel for ushlex (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ushlex: filename=ushlex-0.99.1-py3-none-any.whl size=4436 sha256=3655d9a86d53256ee6737b1830060d63a8ec82922e5cad4461ad06fd604c734b\n",
      "  Stored in directory: /home/zeus/.cache/pip/wheels/42/29/49/bde2276505cc99295263e8ab2fbfd83162b3380b4b571b03bc\n",
      "Successfully built SimpleWebSocketServer typing ushlex\n",
      "Installing collected packages: ushlex, SimpleWebSocketServer, typing, rfc3986, pyparsing, pillow, nh3, more-itertools, kiwisolver, jeepney, jaraco.context, id, fonttools, docutils, cycler, contourpy, requests-toolbelt, readme-renderer, matplotlib, jaraco.functools, jaraco.classes, cryptography, SecretStorage, keyring, twine, pyloco, matplot\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27/27\u001b[0m [matplot]5/27\u001b[0m [pyloco]raphy]belt]\n",
      "\u001b[1A\u001b[2KSuccessfully installed SecretStorage-3.5.0 SimpleWebSocketServer-0.1.2 contourpy-1.3.3 cryptography-46.0.5 cycler-0.12.1 docutils-0.22.4 fonttools-4.61.1 id-1.6.1 jaraco.classes-3.4.0 jaraco.context-6.1.0 jaraco.functools-4.4.0 jeepney-0.9.0 keyring-25.7.0 kiwisolver-1.4.9 matplot-0.1.9 matplotlib-3.10.8 more-itertools-10.8.0 nh3-0.3.3 pillow-12.1.1 pyloco-0.0.139 pyparsing-3.3.2 readme-renderer-44.0 requests-toolbelt-1.0.0 rfc3986-2.0.0 twine-6.2.0 typing-3.7.4.3 ushlex-0.99.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m26.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install matplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                     # embedding and math\n",
    "import os\n",
    "import re                              # remove noise\n",
    "import pandas as pd                    # clean the Q&A\n",
    "import torch                           # deep learning framework\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "from transformers import BitsAndBytesConfig\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,             # converts text => numbers(tokens)\n",
    "    AutoModelForCausalLM,       #\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from datasets import load_from_disk, load_dataset\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /teamspace/studios/this_studio/.cache/kagglehub/datasets/rodasgoniche/seeker/versions/1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>entry_type</th>\n",
       "      <th>target_audience</th>\n",
       "      <th>role</th>\n",
       "      <th>region</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>ml_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ats_keywords</td>\n",
       "      <td>all_job_seekers</td>\n",
       "      <td>UX Designer</td>\n",
       "      <td>Africa</td>\n",
       "      <td>What ATS keywords should a UX Designer include...</td>\n",
       "      <td>Include keywords such as ux designer, core too...</td>\n",
       "      <td>finetuning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>mock_interview</td>\n",
       "      <td>all_job_seekers</td>\n",
       "      <td>UX Designer</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Mock interview question for an entry-level UX ...</td>\n",
       "      <td>Describe a project where you applied relevant ...</td>\n",
       "      <td>finetuning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ats_keywords</td>\n",
       "      <td>all_job_seekers</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Global Remote</td>\n",
       "      <td>What ATS keywords should a Data Analyst includ...</td>\n",
       "      <td>Include keywords such as data analyst, core to...</td>\n",
       "      <td>finetuning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ats_keywords</td>\n",
       "      <td>all_job_seekers</td>\n",
       "      <td>IT Support</td>\n",
       "      <td>US/EU</td>\n",
       "      <td>What ATS keywords should a IT Support include ...</td>\n",
       "      <td>Include keywords such as it support, core tool...</td>\n",
       "      <td>finetuning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>resume_rewrite</td>\n",
       "      <td>all_job_seekers</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Rewrite this resume bullet for a Data Analyst:...</td>\n",
       "      <td>Bad: Worked on projects and helped the team. |...</td>\n",
       "      <td>finetuning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id      entry_type  target_audience          role         region  \\\n",
       "0   1    ats_keywords  all_job_seekers   UX Designer         Africa   \n",
       "1   2  mock_interview  all_job_seekers   UX Designer         Africa   \n",
       "2   3    ats_keywords  all_job_seekers  Data Analyst  Global Remote   \n",
       "3   4    ats_keywords  all_job_seekers    IT Support          US/EU   \n",
       "4   5  resume_rewrite  all_job_seekers  Data Analyst         Africa   \n",
       "\n",
       "                                            question  \\\n",
       "0  What ATS keywords should a UX Designer include...   \n",
       "1  Mock interview question for an entry-level UX ...   \n",
       "2  What ATS keywords should a Data Analyst includ...   \n",
       "3  What ATS keywords should a IT Support include ...   \n",
       "4  Rewrite this resume bullet for a Data Analyst:...   \n",
       "\n",
       "                                              answer      ml_tag  \n",
       "0  Include keywords such as ux designer, core too...  finetuning  \n",
       "1  Describe a project where you applied relevant ...  finetuning  \n",
       "2  Include keywords such as data analyst, core to...  finetuning  \n",
       "3  Include keywords such as it support, core tool...  finetuning  \n",
       "4  Bad: Worked on projects and helped the team. |...  finetuning  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download the dataset\n",
    "path = kagglehub.dataset_download(\"rodasgoniche/seeker\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "# Construct the full path to the CSV file\n",
    "csv_file_path = os.path.join(path, \"career__dataset_3000.csv\")\n",
    "# Read the CSV file using the correct path\n",
    "df = pd.read_csv(csv_file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# clean the dataset\n",
    "def clean_text(text):\n",
    "  text = str(text)\n",
    "\n",
    "  # remove extra spaces\n",
    "  text = re.sub(r\"\\s+\", \" \", text)\n",
    "  # remove weird characters except punctuation\n",
    "  text = re.sub(r\"[^a-zA-Z0-9.,!?;:'\\\"()\\- ]\", \"\", text)\n",
    "  # strip trailing spaces\n",
    "  text = text.strip()\n",
    "\n",
    "  return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the cleaning\n",
    "df[\"question\"] = df[\"question\"].apply(clean_text)\n",
    "df[\"answer\"] = df[\"answer\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove empty or bad rows\n",
    "df = df.dropna()\n",
    "df= df[df[\"question\"].str.len() > 5]\n",
    "df = df[df[\"answer\"].str.len() > 5]\n",
    "df = df.drop_duplicates()\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset size: 3000\n",
      "                                            question  \\\n",
      "0  What ATS keywords should a UX Designer include...   \n",
      "1  Mock interview question for an entry-level UX ...   \n",
      "2  What ATS keywords should a Data Analyst includ...   \n",
      "3  What ATS keywords should a IT Support include ...   \n",
      "4  Rewrite this resume bullet for a Data Analyst:...   \n",
      "\n",
      "                                              answer  \n",
      "0  Include keywords such as ux designer, core too...  \n",
      "1  Describe a project where you applied relevant ...  \n",
      "2  Include keywords such as data analyst, core to...  \n",
      "3  Include keywords such as it support, core tool...  \n",
      "4  Bad: Worked on projects and helped the team.  ...  \n"
     ]
    }
   ],
   "source": [
    "print(\"Final dataset size:\", len(df))\n",
    "print(df.head(5)[['question', 'answer']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The format_prompt(row) function takes each row of the DataFrame and formats the question and answer columns into a structured prompt. Initially it use a simple ###questions / ###answer format, then redefine the function to use a chat-style format with <|system|>, <|user|>, and <|assistant|> roles (which is better for instruction/chat model training).\n",
    "\n",
    "This part helps in formatting, cleaning, and validating your training data before using it to fine-tune a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|system|>\n",
      "You are a career assistant specializing in resumes and interview preparation.\n",
      "\n",
      "<|user|>\n",
      "What ATS keywords should a UX Designer include for roles in Africa?\n",
      "\n",
      "<|assistant|>\n",
      "Include keywords such as ux designer, core tools, methodologies, and certifications commonly listed in Africa-based job postings.\n",
      "-----\n",
      "<|system|>\n",
      "You are a career assistant specializing in resumes and interview preparation.\n",
      "\n",
      "<|user|>\n",
      "Mock interview question for an entry-level UX Designer role.\n",
      "\n",
      "<|assistant|>\n",
      "Describe a project where you applied relevant skills for a UX Designer. Focus on problem, action, and result.\n",
      "-----\n",
      "<|system|>\n",
      "You are a career assistant specializing in resumes and interview preparation.\n",
      "\n",
      "<|user|>\n",
      "What ATS keywords should a Data Analyst include for roles in Global Remote?\n",
      "\n",
      "<|assistant|>\n",
      "Include keywords such as data analyst, core tools, methodologies, and certifications commonly listed in Global Remote-based job postings.\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "def format_prompt(row):\n",
    "  return f\"\"\"###questions:\n",
    "{row['question']}\n",
    "\n",
    "###answer:\n",
    "{row['answer']}\"\"\"\n",
    "\n",
    "df[\"text\"] = df.apply(format_prompt, axis=1)\n",
    "df[\"text\"].iloc[0]\n",
    "def format_prompt(row):\n",
    "    return f\"\"\"<|system|>\n",
    "You are a career assistant specializing in resumes and interview preparation.\n",
    "\n",
    "<|user|>\n",
    "{row['question']}\n",
    "\n",
    "<|assistant|>\n",
    "{row['answer']}\"\"\"\n",
    "\n",
    "df[\"text\"] = df.apply(format_prompt, axis=1)\n",
    "df[\"text\"].iloc[0]\n",
    "\n",
    "# final check for rows where the question/answer are just punctuation\n",
    "df = df[df['question'].str.strip().str.len() > 0]\n",
    "df = df[df['answer'].str.strip().str.len() > 0]\n",
    "\n",
    "for i in range(3):\n",
    "    print(df['text'].iloc[i])\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 3000\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.from_pandas(df[[\"text\"]])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is splitting my dataset into training and validation sets.\n",
    "\n",
    "dataset.train_test_split(test_size=0.1, seed=42)\n",
    "Splits the dataset into:\n",
    "\n",
    "90% for training\n",
    "\n",
    "10% for validation (testing)\n",
    "* The seed=42 ensures the split is reproducible (so that we get the same split every time we run it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 2700\n",
      "Validation samples: 300\n"
     ]
    }
   ],
   "source": [
    "# Split into train and validation\n",
    "split_dataset = dataset.train_test_split(test_size=0.1, seed=42)\n",
    "train_dataset = split_dataset[\"train\"]\n",
    "eval_dataset = split_dataset[\"test\"]\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(eval_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is preparing the tokenizer for my model.\n",
    "\n",
    "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\" - specifying which pretrained model from Hugging Face I want to use\n",
    "\n",
    "This loads the tokenizer that matches that model which converts text into tokens (numbers) that the model understands.\n",
    "Some models (like TinyLlama) don’t have a default padding token so set the padding token to be the same as the end-of-sequence (eos_token). This prevents errors during batching.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "\n",
    "# load tokenizer/use small model tokenizer for efficiency\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# required for padding\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code prepares my dataset for training a chat model in a way that makes it easier for the model to learn. First, it converts the text into tokens (numbers) that the model can understand, truncating long texts to 512 tokens and padding shorter ones so all sequences are the same length. Then, it creates labels for training: it ignores everything before <|assistant|> (the user’s question and prompt) by setting those tokens to -100, and only uses the tokens after <|assistant|> (the assistant’s reply) as the target for the model to predict. This ensures the model focuses on generating correct answers rather than trying to predict the question. Finally, it applies this process to the entire training and validation datasets and removes the original text column, leaving only the tokenized inputs and labels, making the dataset ready for supervised fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd810c47e00146a2ad9282aaa9f4ad42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2700 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a29fd0844774b1b9146abd7ee40553e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/300 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [1, 529, 29989, 5205, 29989, 29958, 13, 3492, 526, 263, 6413, 20255, 4266, 5281, 297, 620, 9351, 322, 15593, 10223, 362, 29889, 13, 13, 29966, 29989, 1792, 29989, 29958, 13, 5618, 319, 9375, 29361, 881, 263, 13315, 18601, 3160, 363, 16178, 297, 10557, 29973, 13, 13, 29966, 29989, 465, 22137, 29989, 29958, 13, 29419, 29361, 1316, 408, 372, 2304, 29892, 7136, 8492, 29892, 1158, 11763, 29892, 322, 2284, 8232, 15574, 9904, 297, 10557, 29899, 6707, 4982, 1400, 886, 29889, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 13, 29419, 29361, 1316, 408, 372, 2304, 29892, 7136, 8492, 29892, 1158, 11763, 29892, 322, 2284, 8232, 15574, 9904, 297, 10557, 29899, 6707, 4982, 1400, 886, 29889, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]}\n",
      "{'input_ids': [1, 529, 29989, 5205, 29989, 29958, 13, 3492, 526, 263, 6413, 20255, 4266, 5281, 297, 620, 9351, 322, 15593, 10223, 362, 29889, 13, 13, 29966, 29989, 1792, 29989, 29958, 13, 5618, 319, 9375, 29361, 881, 263, 501, 29990, 12037, 261, 3160, 363, 16178, 297, 501, 1660, 29965, 29973, 13, 13, 29966, 29989, 465, 22137, 29989, 29958, 13, 29419, 29361, 1316, 408, 318, 29916, 23383, 29892, 7136, 8492, 29892, 1158, 11763, 29892, 322, 2284, 8232, 15574, 9904, 297, 501, 1660, 29965, 29899, 6707, 4982, 1400, 886, 29889, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 13, 29419, 29361, 1316, 408, 318, 29916, 23383, 29892, 7136, 8492, 29892, 1158, 11763, 29892, 322, 2284, 8232, 15574, 9904, 297, 501, 1660, 29965, 29899, 6707, 4982, 1400, 886, 29889, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]}\n",
      "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 13, 29419, 29361, 1316, 408, 372, 2304, 29892]\n"
     ]
    }
   ],
   "source": [
    "def tokenize(example):\n",
    "    texts = example[\"text\"]\n",
    "\n",
    "    tokenized = tokenizer(\n",
    "        texts,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "    labels = []\n",
    "\n",
    "    for i, input_ids in enumerate(tokenized[\"input_ids\"]):\n",
    "        text = texts[i]\n",
    "\n",
    "        # Find assistant start\n",
    "        assistant_marker = \"<|assistant|>\"\n",
    "        assistant_index = text.find(assistant_marker)\n",
    "\n",
    "        if assistant_index == -1:\n",
    "            labels.append([-100] * len(input_ids))\n",
    "            continue\n",
    "\n",
    "        # Tokenize prefix (everything before assistant answer)\n",
    "        prefix = text[:assistant_index + len(assistant_marker)]\n",
    "        prefix_ids = tokenizer(\n",
    "            prefix,\n",
    "            truncation=True,\n",
    "            max_length=512\n",
    "        )[\"input_ids\"]\n",
    "\n",
    "        assistant_start_token_index = len(prefix_ids)\n",
    "\n",
    "        example_labels = []\n",
    "\n",
    "        for j, token_id in enumerate(input_ids):\n",
    "            if token_id == tokenizer.pad_token_id:\n",
    "                example_labels.append(-100)\n",
    "            elif j < assistant_start_token_index:\n",
    "                example_labels.append(-100)\n",
    "            else:\n",
    "                example_labels.append(token_id)\n",
    "\n",
    "        labels.append(example_labels)\n",
    "\n",
    "    tokenized[\"labels\"] = labels\n",
    "    return tokenized\n",
    "\n",
    "train_tokenized = train_dataset.map(tokenize, batched=True)\n",
    "eval_tokenized = eval_dataset.map(tokenize, batched=True)\n",
    "\n",
    "train_tokenized = train_tokenized.remove_columns([\"text\"])\n",
    "eval_tokenized = eval_tokenized.remove_columns([\"text\"])\n",
    "\n",
    "print(train_tokenized[0])\n",
    "print(eval_tokenized[0])\n",
    "print(train_tokenized[0][\"labels\"][:60])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code sets up a data collator, which is responsible for preparing batches of data during training. It takes the tokenized inputs and labels and combines them into batches the model can process efficiently. Here, DataCollatorForLanguageModeling is used with mlm=False because this is a causal/decoder-only model, not a masked language model. That means the model will predict the next token in the sequence (like a chat response) rather than trying to fill in missing words. Essentially, the collator handles padding, batching, and label alignment automatically so the training loop can run smoothly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this prepares batches during training\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login, upload_folder\n",
    "login(os.getenv(\"HF_Token\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives a baseline score to compare against after the fine-tune the model, so that we can see how much it improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1166ab8bc0d94c2a8d633a65c5d47c07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 02:26]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.688645362854004\n",
      "Baseline Perplexity: 14.711733355537186\n"
     ]
    }
   ],
   "source": [
    "# Load base model WITHOUT quantization\n",
    "baseline_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "baseline_args = TrainingArguments(\n",
    "    output_dir=\"/tmp/baseline\",\n",
    "    per_device_eval_batch_size=2,\n",
    "    do_train=False,\n",
    "    do_eval=True,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "baseline_trainer = Trainer(\n",
    "    model=baseline_model,\n",
    "    args=baseline_args,\n",
    "    eval_dataset=eval_tokenized,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "baseline_results = baseline_trainer.evaluate()\n",
    "baseline_loss = baseline_results[\"eval_loss\"]\n",
    "baseline_perplexity = math.exp(baseline_loss)\n",
    "\n",
    "print(\"Baseline Loss:\", baseline_loss)\n",
    "print(\"Baseline Perplexity:\", baseline_perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a series of experiments to fine-tune a chat model with different hyperparameters and saves the results for comparison. For each experiment, it prints the experiment name, reloads a fresh base model with 8-bit quantization to save memory, and enables gradient checkpointing to reduce GPU usage. It then applies LoRA adapters to the model, which allow efficient fine-tuning by only training small low-rank matrices instead of the full model. Training arguments are set according to the experiment’s learning rate, batch size, number of epochs, optimizer type, and evaluation strategy, including automatic evaluation and early stopping to prevent overfitting. A Trainer object handles the training loop using the tokenized datasets and a data collator to prepare batches. After training, the model is evaluated on the validation set, and the evaluation loss is converted to perplexity to measure prediction quality. The trained LoRA adapters and tokenizer are saved, and all results including hyperparameters, loss, and perplexity are appended to a list, so you can later compare which configuration performed best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      " Running exp1\n",
      "==============================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aef80e5d30e4b96bbee793537a6d201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='450' max='676' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [450/676 35:27 < 17:53, 0.21 it/s, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.281867</td>\n",
       "      <td>0.197238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.080947</td>\n",
       "      <td>0.053733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.051245</td>\n",
       "      <td>0.049323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.046488</td>\n",
       "      <td>0.048448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.046186</td>\n",
       "      <td>0.045939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.045370</td>\n",
       "      <td>0.044260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.045135</td>\n",
       "      <td>0.043651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.044527</td>\n",
       "      <td>0.043694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.042396</td>\n",
       "      <td>0.044008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:28]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp1 done.\n",
      "Eval Loss: 0.0437\n",
      "Perplexity: 1.04\n",
      "\n",
      "==============================\n",
      " Running exp2\n",
      "==============================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0f454d132a94f349e226f358fcfd4c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='676' max='676' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [676/676 53:13, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.840420</td>\n",
       "      <td>0.906377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.375146</td>\n",
       "      <td>0.103413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.072855</td>\n",
       "      <td>0.055824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.052836</td>\n",
       "      <td>0.052017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.050438</td>\n",
       "      <td>0.049684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.049059</td>\n",
       "      <td>0.047463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.048075</td>\n",
       "      <td>0.045994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.046829</td>\n",
       "      <td>0.045391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.044030</td>\n",
       "      <td>0.046779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.045658</td>\n",
       "      <td>0.044885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.044434</td>\n",
       "      <td>0.044461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.044743</td>\n",
       "      <td>0.044615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.044109</td>\n",
       "      <td>0.044331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:28]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp2 done.\n",
      "Eval Loss: 0.0443\n",
      "Perplexity: 1.05\n",
      "\n",
      "==============================\n",
      " Running exp3\n",
      "==============================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d5e00915775467fa14966fd65836e38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='450' max='1014' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 450/1014 35:30 < 44:42, 0.21 it/s, Epoch 1/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.835829</td>\n",
       "      <td>0.894048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.368449</td>\n",
       "      <td>0.109086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.073190</td>\n",
       "      <td>0.055376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.052292</td>\n",
       "      <td>0.050509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.049946</td>\n",
       "      <td>0.050719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.048853</td>\n",
       "      <td>0.049341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.047535</td>\n",
       "      <td>0.045464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.047029</td>\n",
       "      <td>0.045966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.044370</td>\n",
       "      <td>0.045813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:28]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp3 done.\n",
      "Eval Loss: 0.0455\n",
      "Perplexity: 1.05\n",
      "\n",
      "==============================\n",
      " Running exp4\n",
      "==============================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a4d89db05f5414a939f5920d8022648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='650' max='1014' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 650/1014 51:19 < 28:49, 0.21 it/s, Epoch 1/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.251322</td>\n",
       "      <td>1.720085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.143505</td>\n",
       "      <td>0.668543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.379383</td>\n",
       "      <td>0.154123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.099621</td>\n",
       "      <td>0.071893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.063691</td>\n",
       "      <td>0.059689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.056736</td>\n",
       "      <td>0.053143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.053248</td>\n",
       "      <td>0.051006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.051328</td>\n",
       "      <td>0.050780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.048022</td>\n",
       "      <td>0.048953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.049178</td>\n",
       "      <td>0.048127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.047183</td>\n",
       "      <td>0.046224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.048011</td>\n",
       "      <td>0.047005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.046992</td>\n",
       "      <td>0.048184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:28]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp4 done.\n",
      "Eval Loss: 0.0462\n",
      "Perplexity: 1.05\n",
      "\n",
      "==============================\n",
      " Running exp5\n",
      "==============================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ed6ad8d745348ceb1443508863b13f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='338' max='338' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [338/338 45:57, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.832632</td>\n",
       "      <td>0.910934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.411017</td>\n",
       "      <td>0.099475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.069351</td>\n",
       "      <td>0.053918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.052909</td>\n",
       "      <td>0.049408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.048715</td>\n",
       "      <td>0.049048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.047820</td>\n",
       "      <td>0.047224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:28]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp5 done.\n",
      "Eval Loss: 0.0472\n",
      "Perplexity: 1.05\n",
      "\n",
      "==============================\n",
      " Running exp6\n",
      "==============================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e16cc040c4c49078e1895369b8bf2b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='338' max='338' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [338/338 45:53, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.821791</td>\n",
       "      <td>0.886050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.386415</td>\n",
       "      <td>0.096254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.067854</td>\n",
       "      <td>0.055060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.052883</td>\n",
       "      <td>0.051156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.049586</td>\n",
       "      <td>0.049860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.048279</td>\n",
       "      <td>0.048178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:28]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp6 done.\n",
      "Eval Loss: 0.0482\n",
      "Perplexity: 1.05\n",
      "\n",
      "==============================\n",
      " Running exp7\n",
      "==============================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3ad410e51ed4a6288aef6a493e987c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='507' max='507' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [507/507 1:09:20, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.229885</td>\n",
       "      <td>1.694002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.162897</td>\n",
       "      <td>0.674722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.381482</td>\n",
       "      <td>0.163529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.109547</td>\n",
       "      <td>0.075179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.065367</td>\n",
       "      <td>0.058242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.058323</td>\n",
       "      <td>0.054776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.053972</td>\n",
       "      <td>0.052124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.051799</td>\n",
       "      <td>0.052415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.051623</td>\n",
       "      <td>0.050201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.050486</td>\n",
       "      <td>0.050805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:28]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp7 done.\n",
      "Eval Loss: 0.0502\n",
      "Perplexity: 1.05\n"
     ]
    }
   ],
   "source": [
    "experiments = [\n",
    "    {\"name\": \"exp1\", \"lr\": 2e-4, \"batch\": 2, \"epochs\": 2, \"optimizer\": \"paged_adamw_8bit\"},\n",
    "    {\"name\": \"exp2\", \"lr\": 1e-4, \"batch\": 2, \"epochs\": 2, \"optimizer\": \"paged_adamw_8bit\"},\n",
    "    {\"name\": \"exp3\", \"lr\": 1e-4, \"batch\": 2, \"epochs\": 3, \"optimizer\": \"paged_adamw_8bit\"},\n",
    "    {\"name\": \"exp4\", \"lr\": 5e-5, \"batch\": 2, \"epochs\": 3, \"optimizer\": \"paged_adamw_8bit\"},\n",
    "    {\"name\": \"exp5\", \"lr\": 1e-4, \"batch\": 4, \"epochs\": 2, \"optimizer\": \"paged_adamw_8bit\"},\n",
    "    {\"name\": \"exp6\", \"lr\": 1e-4, \"batch\": 4, \"epochs\": 2, \"optimizer\": \"adamw_torch\"},\n",
    "    {\"name\": \"exp7\", \"lr\": 5e-5, \"batch\": 4, \"epochs\": 3, \"optimizer\": \"adamw_torch\"},\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for exp in experiments:\n",
    "    print(f\"\\n==============================\")\n",
    "    print(f\" Running {exp['name']}\")\n",
    "    print(f\"==============================\")\n",
    "\n",
    "    # Reload quantized base model (fresh each experiment)\n",
    "    quant_config = BitsAndBytesConfig(\n",
    "        load_in_8bit=True,\n",
    "        bnb_4bit_compute_dtype=torch.float16,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\"\n",
    "        )\n",
    "\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        quantization_config=quant_config,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "\n",
    "    base_model.gradient_checkpointing_enable()\n",
    "    base_model.config.use_cache = False\n",
    "\n",
    "    # Apply LoRA again (fresh adapters)\n",
    "    lora_config = LoraConfig(\n",
    "        r=8,\n",
    "        lora_alpha=16,\n",
    "        target_modules=[\"q_proj\", \"v_proj\"],\n",
    "        lora_dropout=0.05,\n",
    "        bias=\"none\",\n",
    "        task_type=TaskType.CAUSAL_LM\n",
    "    )\n",
    "\n",
    "    model = get_peft_model(base_model, lora_config)\n",
    "\n",
    "    # Training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"/teamspace/studios/this_studio/career_model_{exp['name']}\",\n",
    "        per_device_train_batch_size=exp[\"batch\"],\n",
    "        gradient_accumulation_steps=4,\n",
    "        learning_rate=exp[\"lr\"],\n",
    "        num_train_epochs=exp[\"epochs\"],\n",
    "        logging_steps=50,\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=50,\n",
    "        eval_strategy=\"steps\", # Changed to 'steps'\n",
    "        eval_steps=50,\n",
    "        save_total_limit=1,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"eval_loss\",\n",
    "        greater_is_better=False,\n",
    "        fp16=True,\n",
    "        optim=exp[\"optimizer\"],\n",
    "        report_to=\"none\"\n",
    "    )\n",
    "\n",
    "    # Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_tokenized,\n",
    "        eval_dataset=eval_tokenized,\n",
    "        data_collator=data_collator,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    "    )\n",
    "\n",
    "    # Train\n",
    "    trainer.train()\n",
    "\n",
    "    # Evaluate\n",
    "    eval_results = trainer.evaluate()\n",
    "    eval_loss = eval_results[\"eval_loss\"]\n",
    "    perplexity = math.exp(eval_loss)\n",
    "\n",
    "    print(f\"{exp['name']} done.\")\n",
    "    print(f\"Eval Loss: {eval_loss:.4f}\")\n",
    "    print(f\"Perplexity: {perplexity:.2f}\")\n",
    "\n",
    "    # Save adapters\n",
    "    trainer.save_model(f\"/tmp/career_model_{exp['name']}_final\")\n",
    "    tokenizer.save_pretrained(f\"/tmp/career_model_{exp['name']}_final\")\n",
    "\n",
    "    # Store results\n",
    "    results.append({\n",
    "        \"experiment\": exp[\"name\"],\n",
    "        \"lr\": exp[\"lr\"],\n",
    "        \"batch\": exp[\"batch\"],\n",
    "        \"epochs\": exp[\"epochs\"],\n",
    "        \"optimizer\": exp[\"optimizer\"],\n",
    "        \"eval_loss\": eval_loss,\n",
    "        \"perplexity\": perplexity\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 358.4860473394394 minutes\n"
     ]
    }
   ],
   "source": [
    "end = time.time()\n",
    "print(\"Training time:\", (end-start)/60, \"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== All experiments completed ===\n",
      "  experiment       lr  batch  epochs         optimizer  eval_loss  perplexity\n",
      "0       exp1  0.00020      2       2  paged_adamw_8bit   0.043651    1.044618\n",
      "1       exp2  0.00010      2       2  paged_adamw_8bit   0.044331    1.045328\n",
      "2       exp3  0.00010      2       3  paged_adamw_8bit   0.045464    1.046514\n",
      "3       exp4  0.00005      2       3  paged_adamw_8bit   0.046224    1.047309\n",
      "4       exp5  0.00010      4       2  paged_adamw_8bit   0.047224    1.048357\n",
      "5       exp6  0.00010      4       2       adamw_torch   0.048178    1.049357\n",
      "6       exp7  0.00005      4       3       adamw_torch   0.050201    1.051482\n"
     ]
    }
   ],
   "source": [
    "df_results = pd.DataFrame(results)\n",
    "df_results = df_results.sort_values(\"perplexity\")\n",
    "df_results.to_csv(\"/teamspace/studios/this_studio/hyperparameter_experiments_results.csv\", index=False)\n",
    "print(\"\\n=== All experiments completed ===\")\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best Experiment is: exp1\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained(\"/teamspace/studios/this_studio/career_finetuned\")\n",
    "tokenizer.save_pretrained(\"/teamspace/studios/this_studio/career_finetuned\")\n",
    "best_exp = df_results.iloc[0][\"experiment\"]\n",
    "print(\"The best Experiment is:\", best_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model path: /teamspace/studios/this_studio/career_model_exp1_final\n"
     ]
    }
   ],
   "source": [
    "best_model_path = f\"/teamspace/studios/this_studio/career_model_{best_exp}_final\"\n",
    "print(\"Best model path:\", best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this code below loads the LoRA-fine-tuned TinyLlama, formats a chat-style prompt, generates a career-assistant response, and saves the model for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acb31c8c8a6b486da5432d9230358a5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing `generation_config` together with generation-related arguments=({'temperature', 'max_new_tokens', 'top_p', 'do_sample'}) is deprecated and will be removed in future versions. Please pass either a `generation_config` object OR all generation parameters explicitly, but not both.\n",
      "Both `max_new_tokens` (=300) and `max_length`(=2048) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|system|>\n",
      "You are a professional career assistant.</s>\n",
      "<|user|>\n",
      "Improve this resume summary for a software developer.</s>\n",
      "<|assistant|>\n",
      "Job: Software Developer \n",
      "\n",
      "Summary: Partnering with a team to create high-quality applications for remote work. \n",
      "\n",
      "Keywords: Software Development, Remote, Team, Creation, Remote Work\n",
      "\n",
      "Relevant skills: Adapting to remote work, Collaborating with teams, Designing and implementing applications\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/teamspace/studios/this_studio/career_finetuned/tokenizer_config.json',\n",
       " '/teamspace/studios/this_studio/career_finetuned/chat_template.jinja',\n",
       " '/teamspace/studios/this_studio/career_finetuned/tokenizer.json')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "BASE_MODEL = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "ADAPTER_PATH = \"/teamspace/studios/this_studio/career_finetuned\"\n",
    "\n",
    "# tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
    "\n",
    "# base model\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# attach LoRA adapter\n",
    "model = PeftModel.from_pretrained(base_model, ADAPTER_PATH)\n",
    "\n",
    "model.eval()\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a professional career assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Improve this resume summary for a software developer.\"}\n",
    "]\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "result = pipe(\n",
    "    prompt,\n",
    "    max_new_tokens=300,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "    do_sample=True\n",
    ")\n",
    "\n",
    "print(result[0][\"generated_text\"])\n",
    "save_path = \"/teamspace/studios/this_studio/career_finetuned\"\n",
    "model.save_pretrained(save_path)\n",
    "tokenizer.save_pretrained(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_folder(\n",
    "    repo_id=\"helinow/careermate\",\n",
    "    folder_path=save_path,\n",
    "    commit_message=\"Upload fine-tuned career assistant model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting nltk\n",
      "  Downloading nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from evaluate) (4.5.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from evaluate) (2.4.2)\n",
      "Requirement already satisfied: dill in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from evaluate) (0.4.0)\n",
      "Requirement already satisfied: pandas in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from evaluate) (3.0.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from evaluate) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from evaluate) (4.67.3)\n",
      "Requirement already satisfied: xxhash in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from evaluate) (3.6.0)\n",
      "Requirement already satisfied: multiprocess in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from evaluate) (0.70.18)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.10.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from evaluate) (1.4.1)\n",
      "Requirement already satisfied: packaging in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from evaluate) (25.0)\n",
      "Collecting absl-py (from rouge_score)\n",
      "  Downloading absl_py-2.4.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: six>=1.14.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from rouge_score) (1.17.0)\n",
      "Requirement already satisfied: click in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from nltk) (8.3.1)\n",
      "Collecting joblib (from nltk)\n",
      "  Downloading joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from nltk) (2026.2.19)\n",
      "Requirement already satisfied: filelock in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (3.24.3)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (23.0.1)\n",
      "Requirement already satisfied: httpx<1.0.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (0.28.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.3)\n",
      "Requirement already satisfied: anyio in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (4.12.1)\n",
      "Requirement already satisfied: certifi in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0->datasets>=2.0.0->evaluate) (0.16.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.0)\n",
      "Requirement already satisfied: shellingham in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from huggingface-hub>=0.7.0->evaluate) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from huggingface-hub>=0.7.0->evaluate) (0.24.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (2.6.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: typer>=0.24.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from typer-slim->huggingface-hub>=0.7.0->evaluate) (0.24.1)\n",
      "Requirement already satisfied: rich>=12.3.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from typer>=0.24.0->typer-slim->huggingface-hub>=0.7.0->evaluate) (14.3.3)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from typer>=0.24.0->typer-slim->huggingface-hub>=0.7.0->evaluate) (0.0.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->huggingface-hub>=0.7.0->evaluate) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->huggingface-hub>=0.7.0->evaluate) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=12.3.0->typer>=0.24.0->typer-slim->huggingface-hub>=0.7.0->evaluate) (0.1.2)\n",
      "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
      "Downloading nltk-3.9.2-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.4.0-py3-none-any.whl (135 kB)\n",
      "Downloading joblib-1.5.3-py3-none-any.whl (309 kB)\n",
      "Building wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24987 sha256=81f0f45d611b1b522550daa2d6b0cc1b49f01b328f0a7a590786a4760e39d4a5\n",
      "  Stored in directory: /home/zeus/.cache/pip/wheels/85/9d/af/01feefbe7d55ef5468796f0c68225b6788e85d9d0a281e7a70\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: joblib, absl-py, nltk, rouge_score, evaluate\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [evaluate]4/5\u001b[0m [evaluate]\n",
      "\u001b[1A\u001b[2KSuccessfully installed absl-py-2.4.0 evaluate-0.4.6 joblib-1.5.3 nltk-3.9.2 rouge_score-0.1.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m26.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f57eb8461037459884c41d402977a828",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fd5e8dd282d4ecc99c7c061a98cbe68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1adb6c98116e48479888de1e9b45de50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2dd34b382794cd586f11e1e68a03e1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [03:37<00:00,  4.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: {'bleu': 0.4654638484014235, 'precisions': [0.47116875793035384, 0.4674144540678688, 0.4636064636064636, 0.45974362667434826], 'brevity_penalty': 1.0, 'length_ratio': 2.1223818073010174, 'translation_length': 7093, 'reference_length': 3342}\n",
      "ROUGE: {'rouge1': np.float64(0.6251228623588074), 'rouge2': np.float64(0.6203996211251745), 'rougeL': np.float64(0.6247831816435676), 'rougeLsum': np.float64(0.6246501802930141)}\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate rouge_score nltk\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import evaluate\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "def generate_predictions(model, tokenizer, dataset, text_column=\"text\", num_samples=50):\n",
    "    preds, refs = [], []\n",
    "    model.eval()\n",
    "\n",
    "    for i in tqdm(range(min(num_samples, len(dataset)))):\n",
    "        sample = dataset[i][text_column]\n",
    "\n",
    "        inputs = tokenizer(sample, return_tensors=\"pt\", truncation=True).to(model.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model.generate(**inputs, max_new_tokens=100)\n",
    "\n",
    "        pred = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "        preds.append(pred)\n",
    "        refs.append(sample)\n",
    "\n",
    "    return preds, refs\n",
    "\n",
    "\n",
    "predictions, references = generate_predictions(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    eval_dataset\n",
    ")\n",
    "bleu_score = bleu.compute(\n",
    "    predictions=predictions,\n",
    "    references=[[r] for r in references]\n",
    ")\n",
    "\n",
    "rouge_score = rouge.compute(\n",
    "    predictions=predictions,\n",
    "    references=references\n",
    ")\n",
    "\n",
    "print(\"BLEU:\", bleu_score)\n",
    "print(\"ROUGE:\", rouge_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 18.28it/s]\n"
     ]
    }
   ],
   "source": [
    "def calculate_perplexity(model, tokenizer, dataset, text_column=\"text\", num_samples=50):\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for i in tqdm(range(min(num_samples, len(dataset)))):\n",
    "\n",
    "        text = dataset[i][text_column]\n",
    "\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True).to(model.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
    "\n",
    "        losses.append(outputs.loss.item())\n",
    "\n",
    "    avg_loss = sum(losses) / len(losses)\n",
    "    perplexity = math.exp(avg_loss)\n",
    "\n",
    "    return perplexity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BLEU</td>\n",
       "      <td>0.465464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROUGE-1</td>\n",
       "      <td>0.625123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ROUGE-2</td>\n",
       "      <td>0.620400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ROUGE-L</td>\n",
       "      <td>0.624783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Perplexity</td>\n",
       "      <td>1.053394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Metric     Score\n",
       "0        BLEU  0.465464\n",
       "1     ROUGE-1  0.625123\n",
       "2     ROUGE-2  0.620400\n",
       "3     ROUGE-L  0.624783\n",
       "4  Perplexity  1.053394"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    \"Metric\": [\"BLEU\", \"ROUGE-1\", \"ROUGE-2\", \"ROUGE-L\", \"Perplexity\"],\n",
    "    \"Score\": [\n",
    "        bleu_score[\"bleu\"],\n",
    "        rouge_score[\"rouge1\"],\n",
    "        rouge_score[\"rouge2\"],\n",
    "        rouge_score[\"rougeL\"],\n",
    "        ppl\n",
    "    ]\n",
    "})\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "metrics = {\n",
    "    \"BLEU\": bleu_score[\"bleu\"],\n",
    "    \"ROUGE-1\": rouge_score[\"rouge1\"],\n",
    "    \"ROUGE-2\": rouge_score[\"rouge2\"],\n",
    "    \"ROUGE-L\": rouge_score[\"rougeL\"]\n",
    "}\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(metrics.keys(), metrics.values())\n",
    "plt.title(\"Model Evaluation Metrics\")\n",
    "plt.xlabel(\"Metric\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BLEU</td>\n",
       "      <td>0.465464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROUGE-1</td>\n",
       "      <td>0.625123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ROUGE-2</td>\n",
       "      <td>0.620400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ROUGE-L</td>\n",
       "      <td>0.624783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Perplexity</td>\n",
       "      <td>1.053394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Metric     Score\n",
       "0        BLEU  0.465464\n",
       "1     ROUGE-1  0.625123\n",
       "2     ROUGE-2  0.620400\n",
       "3     ROUGE-L  0.624783\n",
       "4  Perplexity  1.053394"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    \"Metric\": [\"BLEU\", \"ROUGE-1\", \"ROUGE-2\", \"ROUGE-L\", \"Perplexity\"],\n",
    "    \"Score\": [\n",
    "        bleu_score[\"bleu\"],\n",
    "        rouge_score[\"rouge1\"],\n",
    "        rouge_score[\"rouge2\"],\n",
    "        rouge_score[\"rougeL\"],\n",
    "        ppl\n",
    "    ]\n",
    "})\n",
    "\n",
    "display(results_df)\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(results_df[\"Metric\"], results_df[\"Score\"])\n",
    "plt.title(\"Overall Model Performance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://github.com/rodwol/chatbot_careermate.git"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
